---
title: "XGBoost-based models and feature selection"
author: "Guiquan"
date: "2021/8/16"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This Rmarkdown is mainly for the construction of XGboost models and feature selection.

# Bayesian Optimization for Hyper Parameters of Strategy models.
## **PORSM**
```{r}
library(tidymodels)
# Data preparation and specifications.
set.seed(777)
porsm_rec <- recipe(POR ~., data = porsm_train) %>% 
  step_dummy(all_nominal_predictors())
porsm_mod_spec <- 
  boost_tree(trees = tune(), 
             min_n = tune(), 
             tree_depth = tune(),
             loss_reduction = tune(),
             sample_size = tune(),
             learn_rate = tune(), 
             mtry = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
porsm_workflow_spec <- workflow() %>% 
  add_model(porsm_mod_spec) %>% 
  add_recipe(porsm_rec)
porsm_bayes_params <- parameters(porsm_workflow_spec) %>% 
  update(mtry = finalize(mtry(), porsm_train), 
         trees = trees(range = c(100L, 1000L)))
# Create cross-validation resamples.
set.seed(777)
porsm_valset <- vfold_cv(porsm_train, v = 5, strata = POR)
# Start tuning.
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
porsm_bayes_regs <- tune_bayes(
  porsm_workflow_spec,
  resamples = porsm_valset,
  param_info = porsm_bayes_params,
  iter = 100,
  metrics = metric_set(roc_auc, mn_log_loss),
  control = control_bayes(no_improve = 50, verbose = TRUE)
)
parallel::stopCluster(cl)
```

## **HORSM**
```{r}
# Data preparation and specifications.
set.seed(777)
horsm_rec <- recipe(HOR ~., data = horsm_train) %>% 
  step_dummy(all_nominal_predictors())
horsm_mod_spec <- 
  boost_tree(trees = tune(), 
             min_n = tune(), 
             tree_depth = tune(),
             loss_reduction = tune(),
             learn_rate = tune(), 
             sample_size = tune(), 
             mtry = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
horsm_workflow_spec <- workflow() %>% 
  add_model(horsm_mod_spec) %>% 
  add_recipe(horsm_rec)
horsm_bayes_params <- parameters(horsm_workflow_spec) %>% 
  update(mtry = finalize(mtry(), horsm_train),
         trees = trees(range = c(100L, 1000L)))
# Create cross-validation resamples.
set.seed(777)
horsm_valset <- vfold_cv(horsm_train, v = 5, strata = HOR)
# Start tuning.
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
horsm_bayes_regs <- tune_bayes(
  horsm_workflow_spec,
  resamples = horsm_valset,
  param_info = horsm_bayes_params,
  iter = 100,
  metrics = metric_set(roc_auc, mn_log_loss),
  control = control_bayes(no_improve = 50, verbose = TRUE)
)
parallel::stopCluster(cl)
show_best(horsm_bayes_regs)
```

# Construction of Strategy models and calculate AUC/Brier score.
## Developing models.
```{r}
set.seed(777)
# Strategy models on train data.
porsm <- select_best(porsm_bayes_regs, "roc_auc") %>% 
  finalize_workflow(porsm_workflow_spec, .) %>% 
  fit(., porsm_train)
horsm <- select_best(horsm_bayes_regs, "roc_auc") %>% 
  finalize_workflow(horsm_workflow_spec, .) %>% 
  fit(., horsm_train)
```
## Calculate AUC and Brier score.
```{r}
# AUC and 95%CI.
set.seed(777)
roc_porsm <- porsm_test %>% 
  select(POR) %>% 
  bind_cols(predict(porsm, porsm_test, type = "prob")) %>% 
  sjmisc::rec(POR, rec = "No = 0; Yes = 1") %>% 
  select(-c(.pred_Yes, POR)) %>% 
  pROC::roc(POR_r, .pred_No, auc = TRUE)
roc_porsm %>% pROC::ci.auc(method = "bootstrap")
roc_horsm <- horsm_test %>% 
  select(HOR) %>% 
  bind_cols(predict(horsm, horsm_test, type = "prob")) %>% 
  sjmisc::rec(HOR, rec = "No = 0; Yes = 1") %>% 
  select(-c(.pred_Yes, HOR)) %>% 
  pROC::roc(HOR_r, .pred_No, auc = TRUE)
roc_horsm %>% pROC::ci.auc(method = "bootstrap")

# Brier score.
brier_score <- function(preds, obs) {
  mean((obs - preds)^2)
}
preds_porsm <- predict(porsm, porsm_test, type = "prob") %>% .[[".pred_Yes"]] 
obs_porsm <- porsm_test %>% select(POR) %>% sjmisc::rec(., rec = "No = 0; Yes = 1") %>% .[["POR_r"]] %>%
  as.character()%>% as.numeric()
brier_score(obs_porsm, preds_porsm)

preds_horsm <- predict(horsm, horsm_test, type = "prob") %>% .[[".pred_Yes"]] 
obs_horsm <- horsm_test %>% select(HOR) %>% sjmisc::rec(., rec = "No = 0; Yes = 1") %>% .[["HOR_r"]] %>%
  as.character()%>% as.numeric()
brier_score(obs_horsm, preds_horsm)
```

# Feature selection through SHAP-based importance.
## Construction PORSM and HORSM on the whole data.
### Tuning parameters.
```{r}
# Tuning for PORSM
porsm_whole_rec <- recipe(POR ~ ., data = porsm_data) %>% 
  step_dummy(all_nominal_predictors())
porsm_whole_workflow <- workflow() %>% 
  add_model(porsm_mod_spec) %>% 
  add_recipe(porsm_whole_rec)
porsm_whole_bayes_params <- parameters(porsm_whole_workflow) %>% 
  update(mtry = finalize(mtry(), porsm_data),
         trees = trees(range = c(100L, 1000L)))

set.seed(777)
porsm_whole_valset <- vfold_cv(porsm_data, v = 5, strata = POR)
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
porsm_whole_bayes_regs <- tune_bayes(
  porsm_whole_workflow,
  resamples = porsm_whole_valset,
  param_info = porsm_whole_bayes_params,
  iter = 100, 
  metrics = metric_set(roc_auc),
  control = control_bayes(no_improve = 50, verbose = TRUE)
)
parallel::stopCluster(cl)

# Tuning for HORSM
horsm_whole_rec <- recipe(HOR ~ ., horsm_data) %>% 
  step_dummy(all_nominal_predictors())
horsm_whole_workflow <- workflow() %>% 
  add_model(horsm_mod_spec) %>% 
  add_recipe(horsm_whole_rec)
horsm_whole_bayes_params <- parameters(horsm_whole_workflow) %>% 
  update(mtry = finalize(mtry(), horsm_data),
         trees = trees(range = c(100L, 1000L)))

set.seed(777)
horsm_whole_valset <- vfold_cv(horsm_data, v = 5, strata = HOR)
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
horsm_whole_bayes_regs <- tune_bayes(
  horsm_whole_workflow,
  resamples = horsm_whole_valset,
  param_info = horsm_whole_bayes_params,
  iter = 100, 
  metrics = metric_set(roc_auc),
  control = control_bayes(no_improve = 50, verbose = TRUE)
)
parallel::stopCluster(cl)
```

### Feature selection of **PORSM**
```{r}
set.seed(777)
porsm_whole <- select_best(porsm_whole_bayes_regs, "roc_auc") %>% 
  finalize_workflow(porsm_whole_workflow, .) %>% 
  fit(., porsm_data)

library(SHAPforxgboost)
porsm_data_forshap <- porsm_whole_rec %>% 
  prep() %>% bake(new_data = NULL) %>% 
  select(-POR) %>% 
  as.matrix()
set.seed(777)
porsm_shap_prep_30 <- shap.prep(xgb_model = extract_fit_engine(porsm_whole),
                          X_train = porsm_data_forshap, 
                          top_n = 30) 
porsm_shap_prep <- shap.prep(xgb_model = extract_fit_engine(porsm_whole),
                          X_train = porsm_data_forshap) 
shap.importance(porsm_shap_prep) %>% 
  openxlsx::write.xlsx(., file = "shap_porsm.xlsx")
```

### Feature selection of **HORSM**
```{r}
set.seed(777)
horsm_whole <- select_best(horsm_whole_bayes_regs, "roc_auc") %>% 
  finalize_workflow(horsm_whole_workflow, .) %>% 
  fit(., horsm_data)

library(SHAPforxgboost)
horsm_data_forshap <- horsm_whole_rec %>% 
  prep() %>% bake(new_data = NULL) %>% 
  select(-HOR) %>% 
  as.matrix()
set.seed(777)
horsm_shap_prep <- shap.prep(xgb_model = extract_fit_engine(horsm_whole),
                          X_train = horsm_data_forshap) 
horsm_shap_prep_30 <- shap.prep(xgb_model = extract_fit_engine(horsm_whole),
                          X_train = horsm_data_forshap,
                          top_n = 30)
shap.importance(horsm_shap_prep) %>% 
  openxlsx::write.xlsx(., file = "shap_horsm.xlsx")
```

# Construction of diagnostic models.
## Bayesian Optimization for Hyper Parameters of Diagnostic models.
### **PORDM**
```{r}
library(tidymodels)
# Data preparation and specifications.
pordm_train <- porsm_train %>% 
  select(-Protocol, Initial.FSH, Recombinant, Use.LH)
pordm_test <- porsm_test %>% 
  select(-Protocol, Initial.FSH, Recombinant, Use.LH)
set.seed(777)
pordm_rec <- recipe(POR ~., data = pordm_train) %>% 
  step_dummy(all_nominal_predictors())
pordm_mod_spec <- 
  boost_tree(trees = tune(), 
             min_n = tune(), 
             tree_depth = tune(),
             loss_reduction = tune(),
             sample_size = tune(),
             learn_rate = tune(), 
             mtry = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
pordm_workflow_spec <- workflow() %>% 
  add_model(pordm_mod_spec) %>% 
  add_recipe(pordm_rec)
pordm_bayes_params <- parameters(pordm_workflow_spec) %>% 
  update(mtry = finalize(mtry(), pordm_train), 
         trees = trees(range = c(100L, 1000L)))
# Create cross-validation resamples.
set.seed(777)
pordm_valset <- vfold_cv(pordm_train, v = 5, strata = POR)
# Start tuning.
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
pordm_bayes_regs <- tune_bayes(
  pordm_workflow_spec,
  resamples = pordm_valset,
  param_info = pordm_bayes_params,
  iter = 100,
  metrics = metric_set(roc_auc, mn_log_loss),
  control = control_bayes(no_improve = 50, verbose = TRUE)
)
parallel::stopCluster(cl)
```

## **HORDM**
```{r}
# Data preparation and specifications.
hordm_train <- horsm_train %>% 
  select(-Protocol, Initial.FSH, Recombinant, Use.LH)
hordm_test <- horsm_test %>% 
  select(-Protocol, Initial.FSH, Recombinant, Use.LH)
set.seed(777)
hordm_rec <- recipe(HOR ~., data = hordm_train) %>% 
  step_dummy(all_nominal_predictors())
hordm_mod_spec <- 
  boost_tree(trees = tune(), 
             min_n = tune(), 
             tree_depth = tune(),
             loss_reduction = tune(),
             learn_rate = tune(), 
             sample_size = tune(), 
             mtry = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
hordm_workflow_spec <- workflow() %>% 
  add_model(hordm_mod_spec) %>% 
  add_recipe(hordm_rec)
hordm_bayes_params <- parameters(hordm_workflow_spec) %>% 
  update(mtry = finalize(mtry(), hordm_train),
         trees = trees(range = c(100L, 1000L)))
# Create cross-validation resamples.
set.seed(777)
hordm_valset <- vfold_cv(hordm_train, v = 5, strata = HOR)
# Start tuning.
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
hordm_bayes_regs <- tune_bayes(
  hordm_workflow_spec,
  resamples = hordm_valset,
  param_info = hordm_bayes_params,
  iter = 100,
  metrics = metric_set(roc_auc, mn_log_loss),
  control = control_bayes(no_improve = 50, verbose = TRUE)
)
parallel::stopCluster(cl)
```

## Construction of Diagnosis models and calculate AUC/Brier score.
### Developing models.
```{r}
set.seed(777)
# Diagnosis models on train data.
pordm <- select_best(pordm_bayes_regs, "roc_auc") %>% 
  finalize_workflow(pordm_workflow_spec, .) %>% 
  fit(., pordm_train)
hordm <- select_best(hordm_bayes_regs, "roc_auc") %>% 
  finalize_workflow(hordm_workflow_spec, .) %>% 
  fit(., hordm_train)
```
## Calculate AUC and Brier score.
```{r}
# AUC and 95%CI.
set.seed(777)
roc_pordm <- pordm_test %>% 
  select(POR) %>% 
  bind_cols(predict(pordm, pordm_test, type = "prob")) %>% 
  sjmisc::rec(POR, rec = "No = 0; Yes = 1") %>% 
  select(-c(.pred_Yes, POR)) %>% 
  pROC::roc(POR_r, .pred_No, auc = TRUE)
roc_pordm %>% pROC::ci.auc(method = "bootstrap")
roc_hordm <- hordm_test %>% 
  select(HOR) %>% 
  bind_cols(predict(hordm, hordm_test, type = "prob")) %>% 
  sjmisc::rec(HOR, rec = "No = 0; Yes = 1") %>% 
  select(-c(.pred_Yes, HOR)) %>% 
  pROC::roc(HOR_r, .pred_No, auc = TRUE)
roc_hordm %>% pROC::ci.auc(method = "bootstrap")

# Brier score.
brier_score <- function(preds, obs) {
  mean((obs - preds)^2)
}
preds_pordm <- predict(pordm, pordm_test, type = "prob") %>% .[[".pred_Yes"]] 
obs_pordm <- pordm_test %>% select(POR) %>% sjmisc::rec(., rec = "No = 0; Yes = 1") %>% .[["POR_r"]] %>%
  as.character()%>% as.numeric()
brier_score(obs_pordm, preds_pordm)

preds_hordm <- predict(hordm, hordm_test, type = "prob") %>% .[[".pred_Yes"]] 
obs_hordm <- hordm_test %>% select(HOR) %>% sjmisc::rec(., rec = "No = 0; Yes = 1") %>% .[["HOR_r"]] %>%
  as.character()%>% as.numeric()
brier_score(obs_hordm, preds_hordm)
```

# Export roc objects for plotting ROC.
```{r}
roc_xgboost_porsm <- roc_porsm
roc_xgboost_horsm <- roc_horsm
save(roc_xgboost_porsm, roc_xgboost_horsm, 
     file = "roc_xgboost.RData")
```




















